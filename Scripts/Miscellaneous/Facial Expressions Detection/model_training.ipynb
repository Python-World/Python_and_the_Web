{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Dense,\n",
    ")\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation using Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"./Data/train\"\n",
    "test_data_path = \"./Data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=20,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_generator = ImageDataGenerator(rescale=1.0 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19211 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "training_data = train_data_generator.flow_from_directory(\n",
    "    directory=train_data_path,\n",
    "    target_size=(48, 48),\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4810 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "testing_data = test_data_generator.flow_from_directory(\n",
    "    directory=test_data_path,\n",
    "    target_size=(48, 48),\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': 0, 'happy': 1, 'sad': 2, 'surprise': 3}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    Conv2D(32, 3, input_shape=(48, 48, 1), activation=\"relu\", padding=\"same\")\n",
    ")\n",
    "model.add(MaxPooling2D((2, 2), strides=2))\n",
    "model.add(Conv2D(64, 3, activation=\"relu\", padding=\"same\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D((2, 2), strides=2))\n",
    "model.add(Conv2D(64, 3, activation=\"relu\", padding=\"same\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D((2, 2), strides=2))\n",
    "model.add(Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 6, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 18436     \n",
      "=================================================================\n",
      "Total params: 148,036\n",
      "Trainable params: 148,036\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-b457966e72cc>:2: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/300\n",
      "301/301 [==============================] - 52s 174ms/step - loss: 1.2734 - accuracy: 0.4193 - val_loss: 1.1668 - val_accuracy: 0.5127\n",
      "Epoch 2/300\n",
      "301/301 [==============================] - 69s 230ms/step - loss: 1.1240 - accuracy: 0.5115 - val_loss: 1.0054 - val_accuracy: 0.5794\n",
      "Epoch 3/300\n",
      "301/301 [==============================] - 69s 229ms/step - loss: 1.0231 - accuracy: 0.5585 - val_loss: 0.9781 - val_accuracy: 0.6031\n",
      "Epoch 4/300\n",
      "301/301 [==============================] - 73s 243ms/step - loss: 0.9562 - accuracy: 0.5972 - val_loss: 0.8870 - val_accuracy: 0.6391\n",
      "Epoch 5/300\n",
      "301/301 [==============================] - 71s 235ms/step - loss: 0.8966 - accuracy: 0.6267 - val_loss: 0.8558 - val_accuracy: 0.6665\n",
      "Epoch 6/300\n",
      "301/301 [==============================] - 63s 210ms/step - loss: 0.8555 - accuracy: 0.6449 - val_loss: 0.7836 - val_accuracy: 0.6811\n",
      "Epoch 7/300\n",
      "301/301 [==============================] - 66s 218ms/step - loss: 0.8250 - accuracy: 0.6621 - val_loss: 0.7667 - val_accuracy: 0.6863\n",
      "Epoch 8/300\n",
      "301/301 [==============================] - 62s 206ms/step - loss: 0.7979 - accuracy: 0.6730 - val_loss: 0.7225 - val_accuracy: 0.7170\n",
      "Epoch 9/300\n",
      "301/301 [==============================] - 70s 232ms/step - loss: 0.7718 - accuracy: 0.6858 - val_loss: 0.7273 - val_accuracy: 0.7087\n",
      "Epoch 10/300\n",
      "301/301 [==============================] - 71s 235ms/step - loss: 0.7596 - accuracy: 0.6915 - val_loss: 0.7112 - val_accuracy: 0.7139\n",
      "Epoch 11/300\n",
      "301/301 [==============================] - 69s 230ms/step - loss: 0.7328 - accuracy: 0.7003 - val_loss: 0.6855 - val_accuracy: 0.7281\n",
      "Epoch 12/300\n",
      "301/301 [==============================] - 64s 213ms/step - loss: 0.7225 - accuracy: 0.7113 - val_loss: 0.7018 - val_accuracy: 0.7183\n",
      "Epoch 13/300\n",
      "301/301 [==============================] - 64s 213ms/step - loss: 0.7135 - accuracy: 0.7120 - val_loss: 0.6810 - val_accuracy: 0.7360\n",
      "Epoch 14/300\n",
      "301/301 [==============================] - 64s 213ms/step - loss: 0.7020 - accuracy: 0.7141 - val_loss: 0.6719 - val_accuracy: 0.7356\n",
      "Epoch 15/300\n",
      "301/301 [==============================] - 66s 219ms/step - loss: 0.6977 - accuracy: 0.7216 - val_loss: 0.6596 - val_accuracy: 0.7491\n",
      "Epoch 16/300\n",
      "301/301 [==============================] - 70s 232ms/step - loss: 0.6894 - accuracy: 0.7230 - val_loss: 0.6600 - val_accuracy: 0.7399\n",
      "Epoch 17/300\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.6751 - accuracy: 0.7310 - val_loss: 0.6696 - val_accuracy: 0.7410\n",
      "Epoch 18/300\n",
      "301/301 [==============================] - 60s 201ms/step - loss: 0.6710 - accuracy: 0.7292 - val_loss: 0.6703 - val_accuracy: 0.7401\n",
      "Epoch 19/300\n",
      "301/301 [==============================] - 62s 207ms/step - loss: 0.6693 - accuracy: 0.7305 - val_loss: 0.6671 - val_accuracy: 0.7418\n",
      "Epoch 20/300\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.6606 - accuracy: 0.7361 - val_loss: 0.6511 - val_accuracy: 0.7459\n",
      "Epoch 21/300\n",
      "301/301 [==============================] - 69s 229ms/step - loss: 0.6545 - accuracy: 0.7359 - val_loss: 0.6322 - val_accuracy: 0.7459\n",
      "Epoch 22/300\n",
      "301/301 [==============================] - 67s 221ms/step - loss: 0.6484 - accuracy: 0.7405 - val_loss: 0.6614 - val_accuracy: 0.7397\n",
      "Epoch 23/300\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.6462 - accuracy: 0.7418 - val_loss: 0.6367 - val_accuracy: 0.7538\n",
      "Epoch 24/300\n",
      "301/301 [==============================] - 63s 210ms/step - loss: 0.6395 - accuracy: 0.7436 - val_loss: 0.6193 - val_accuracy: 0.7551\n",
      "Epoch 25/300\n",
      "301/301 [==============================] - 63s 211ms/step - loss: 0.6280 - accuracy: 0.7515 - val_loss: 0.6339 - val_accuracy: 0.7520\n",
      "Epoch 26/300\n",
      "301/301 [==============================] - 63s 209ms/step - loss: 0.6309 - accuracy: 0.7490 - val_loss: 0.6253 - val_accuracy: 0.7638\n",
      "Epoch 27/300\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.6189 - accuracy: 0.7560 - val_loss: 0.6303 - val_accuracy: 0.7543\n",
      "Epoch 28/300\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.6220 - accuracy: 0.7536 - val_loss: 0.6096 - val_accuracy: 0.7649\n",
      "Epoch 29/300\n",
      "301/301 [==============================] - 70s 231ms/step - loss: 0.6100 - accuracy: 0.7573 - val_loss: 0.6038 - val_accuracy: 0.7640\n",
      "Epoch 30/300\n",
      "301/301 [==============================] - 63s 211ms/step - loss: 0.6023 - accuracy: 0.7641 - val_loss: 0.6330 - val_accuracy: 0.7545\n",
      "Epoch 31/300\n",
      "301/301 [==============================] - 63s 208ms/step - loss: 0.6088 - accuracy: 0.7588 - val_loss: 0.6015 - val_accuracy: 0.7578\n",
      "Epoch 32/300\n",
      "301/301 [==============================] - 62s 205ms/step - loss: 0.6075 - accuracy: 0.7596 - val_loss: 0.6390 - val_accuracy: 0.7499\n",
      "Epoch 33/300\n",
      "301/301 [==============================] - 69s 230ms/step - loss: 0.5997 - accuracy: 0.7596 - val_loss: 0.6006 - val_accuracy: 0.7644\n",
      "Epoch 34/300\n",
      "301/301 [==============================] - 70s 232ms/step - loss: 0.5941 - accuracy: 0.7666 - val_loss: 0.6341 - val_accuracy: 0.7555\n",
      "Epoch 35/300\n",
      "301/301 [==============================] - 67s 223ms/step - loss: 0.5907 - accuracy: 0.7682 - val_loss: 0.5983 - val_accuracy: 0.7605\n",
      "Epoch 36/300\n",
      "301/301 [==============================] - 62s 207ms/step - loss: 0.5899 - accuracy: 0.7698 - val_loss: 0.6105 - val_accuracy: 0.7661\n",
      "Epoch 37/300\n",
      "301/301 [==============================] - 65s 215ms/step - loss: 0.5893 - accuracy: 0.7705 - val_loss: 0.5950 - val_accuracy: 0.7742\n",
      "Epoch 38/300\n",
      "301/301 [==============================] - 64s 211ms/step - loss: 0.5896 - accuracy: 0.7665 - val_loss: 0.6165 - val_accuracy: 0.7640\n",
      "Epoch 39/300\n",
      "301/301 [==============================] - 70s 231ms/step - loss: 0.5863 - accuracy: 0.7692 - val_loss: 0.6119 - val_accuracy: 0.7669\n",
      "Epoch 40/300\n",
      "301/301 [==============================] - 70s 232ms/step - loss: 0.5763 - accuracy: 0.7709 - val_loss: 0.6042 - val_accuracy: 0.7634\n",
      "Epoch 41/300\n",
      "301/301 [==============================] - 64s 214ms/step - loss: 0.5780 - accuracy: 0.7711 - val_loss: 0.6182 - val_accuracy: 0.7572\n",
      "Epoch 42/300\n",
      "301/301 [==============================] - 62s 206ms/step - loss: 0.5718 - accuracy: 0.7750 - val_loss: 0.6148 - val_accuracy: 0.7609\n",
      "Epoch 43/300\n",
      "301/301 [==============================] - 66s 219ms/step - loss: 0.5762 - accuracy: 0.7748 - val_loss: 0.6034 - val_accuracy: 0.7663\n",
      "Epoch 44/300\n",
      "301/301 [==============================] - 65s 216ms/step - loss: 0.5776 - accuracy: 0.7746 - val_loss: 0.5925 - val_accuracy: 0.7699\n",
      "Epoch 45/300\n",
      "301/301 [==============================] - 69s 230ms/step - loss: 0.5688 - accuracy: 0.7739 - val_loss: 0.6219 - val_accuracy: 0.7642\n",
      "Epoch 46/300\n",
      "301/301 [==============================] - 72s 239ms/step - loss: 0.5641 - accuracy: 0.7781 - val_loss: 0.6059 - val_accuracy: 0.7563\n",
      "Epoch 47/300\n",
      "301/301 [==============================] - 70s 232ms/step - loss: 0.5644 - accuracy: 0.7780 - val_loss: 0.5844 - val_accuracy: 0.7742\n",
      "Epoch 48/300\n",
      "301/301 [==============================] - 64s 213ms/step - loss: 0.5609 - accuracy: 0.7786 - val_loss: 0.6062 - val_accuracy: 0.7655\n",
      "Epoch 49/300\n",
      "301/301 [==============================] - 65s 217ms/step - loss: 0.5598 - accuracy: 0.7786 - val_loss: 0.6126 - val_accuracy: 0.7663\n",
      "Epoch 50/300\n",
      "301/301 [==============================] - 70s 233ms/step - loss: 0.5601 - accuracy: 0.7802 - val_loss: 0.5948 - val_accuracy: 0.7728\n",
      "Epoch 51/300\n",
      "301/301 [==============================] - 70s 232ms/step - loss: 0.5527 - accuracy: 0.7777 - val_loss: 0.6033 - val_accuracy: 0.7607\n",
      "Epoch 52/300\n",
      "301/301 [==============================] - 70s 233ms/step - loss: 0.5532 - accuracy: 0.7809 - val_loss: 0.6322 - val_accuracy: 0.7568\n",
      "Epoch 53/300\n",
      "301/301 [==============================] - 70s 234ms/step - loss: 0.5544 - accuracy: 0.7846 - val_loss: 0.5886 - val_accuracy: 0.7701\n",
      "Epoch 54/300\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.5514 - accuracy: 0.7824 - val_loss: 0.6046 - val_accuracy: 0.7669\n",
      "Epoch 55/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 62s 206ms/step - loss: 0.5517 - accuracy: 0.7813 - val_loss: 0.6041 - val_accuracy: 0.7655\n",
      "Epoch 56/300\n",
      "301/301 [==============================] - 64s 212ms/step - loss: 0.5449 - accuracy: 0.7855 - val_loss: 0.6227 - val_accuracy: 0.7617\n",
      "Epoch 57/300\n",
      "301/301 [==============================] - 67s 221ms/step - loss: 0.5488 - accuracy: 0.7844 - val_loss: 0.6199 - val_accuracy: 0.7563\n",
      "Epoch 58/300\n",
      "301/301 [==============================] - 69s 229ms/step - loss: 0.5480 - accuracy: 0.7873 - val_loss: 0.5902 - val_accuracy: 0.7688\n",
      "Epoch 59/300\n",
      "301/301 [==============================] - 72s 238ms/step - loss: 0.5425 - accuracy: 0.7844 - val_loss: 0.6180 - val_accuracy: 0.7709\n",
      "Epoch 60/300\n",
      "301/301 [==============================] - 61s 202ms/step - loss: 0.5431 - accuracy: 0.7870 - val_loss: 0.5927 - val_accuracy: 0.7723\n",
      "Epoch 61/300\n",
      "301/301 [==============================] - 63s 209ms/step - loss: 0.5360 - accuracy: 0.7897 - val_loss: 0.6158 - val_accuracy: 0.7661\n",
      "Epoch 62/300\n",
      "301/301 [==============================] - 67s 221ms/step - loss: 0.5360 - accuracy: 0.7891 - val_loss: 0.5816 - val_accuracy: 0.7753\n",
      "Epoch 63/300\n",
      "301/301 [==============================] - 69s 228ms/step - loss: 0.5322 - accuracy: 0.7934 - val_loss: 0.6036 - val_accuracy: 0.7659\n",
      "Epoch 64/300\n",
      "301/301 [==============================] - 67s 223ms/step - loss: 0.5359 - accuracy: 0.7906 - val_loss: 0.5861 - val_accuracy: 0.7678\n",
      "Epoch 65/300\n",
      "301/301 [==============================] - 62s 206ms/step - loss: 0.5375 - accuracy: 0.7878 - val_loss: 0.5859 - val_accuracy: 0.7742\n",
      "Epoch 66/300\n",
      "301/301 [==============================] - 63s 209ms/step - loss: 0.5388 - accuracy: 0.7908 - val_loss: 0.5885 - val_accuracy: 0.7705\n",
      "Epoch 67/300\n",
      "301/301 [==============================] - 65s 217ms/step - loss: 0.5369 - accuracy: 0.7877 - val_loss: 0.5905 - val_accuracy: 0.7717\n",
      "Epoch 68/300\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.5276 - accuracy: 0.7923 - val_loss: 0.6286 - val_accuracy: 0.7499\n",
      "Epoch 69/300\n",
      "301/301 [==============================] - 67s 222ms/step - loss: 0.5331 - accuracy: 0.7907 - val_loss: 0.5789 - val_accuracy: 0.7755\n",
      "Epoch 70/300\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.5299 - accuracy: 0.7922 - val_loss: 0.5899 - val_accuracy: 0.7711\n",
      "Epoch 71/300\n",
      "301/301 [==============================] - 64s 211ms/step - loss: 0.5258 - accuracy: 0.7914 - val_loss: 0.6062 - val_accuracy: 0.7630\n",
      "Epoch 72/300\n",
      "301/301 [==============================] - 63s 210ms/step - loss: 0.5256 - accuracy: 0.7943 - val_loss: 0.6213 - val_accuracy: 0.7538\n",
      "Epoch 73/300\n",
      "301/301 [==============================] - 64s 212ms/step - loss: 0.5228 - accuracy: 0.7939 - val_loss: 0.6022 - val_accuracy: 0.7686\n",
      "Epoch 74/300\n",
      "301/301 [==============================] - 65s 217ms/step - loss: 0.5273 - accuracy: 0.7921 - val_loss: 0.5779 - val_accuracy: 0.7744\n",
      "Epoch 75/300\n",
      "301/301 [==============================] - 69s 229ms/step - loss: 0.5288 - accuracy: 0.7925 - val_loss: 0.5996 - val_accuracy: 0.7738\n",
      "Epoch 76/300\n",
      "301/301 [==============================] - 71s 235ms/step - loss: 0.5227 - accuracy: 0.7964 - val_loss: 0.6028 - val_accuracy: 0.7688\n",
      "Epoch 77/300\n",
      "301/301 [==============================] - 64s 212ms/step - loss: 0.5234 - accuracy: 0.7929 - val_loss: 0.5850 - val_accuracy: 0.7744\n",
      "Epoch 78/300\n",
      "301/301 [==============================] - 61s 204ms/step - loss: 0.5232 - accuracy: 0.7941 - val_loss: 0.6044 - val_accuracy: 0.7682\n",
      "Epoch 79/300\n",
      "301/301 [==============================] - 66s 219ms/step - loss: 0.5208 - accuracy: 0.7957 - val_loss: 0.6109 - val_accuracy: 0.7626\n",
      "Epoch 80/300\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.5183 - accuracy: 0.7971 - val_loss: 0.6099 - val_accuracy: 0.7634\n",
      "Epoch 81/300\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.5175 - accuracy: 0.7968 - val_loss: 0.5824 - val_accuracy: 0.7719\n",
      "Epoch 82/300\n",
      "301/301 [==============================] - 69s 230ms/step - loss: 0.5132 - accuracy: 0.7983 - val_loss: 0.5885 - val_accuracy: 0.7707\n",
      "Epoch 83/300\n",
      "301/301 [==============================] - 63s 209ms/step - loss: 0.5104 - accuracy: 0.7981 - val_loss: 0.6098 - val_accuracy: 0.7628\n",
      "Epoch 84/300\n",
      "301/301 [==============================] - 63s 210ms/step - loss: 0.5176 - accuracy: 0.7970 - val_loss: 0.5985 - val_accuracy: 0.7674\n",
      "Epoch 85/300\n",
      "301/301 [==============================] - 63s 209ms/step - loss: 0.5161 - accuracy: 0.7996 - val_loss: 0.5890 - val_accuracy: 0.7692\n",
      "Epoch 86/300\n",
      "301/301 [==============================] - 69s 228ms/step - loss: 0.5134 - accuracy: 0.7974 - val_loss: 0.5946 - val_accuracy: 0.7707\n",
      "Epoch 87/300\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.5105 - accuracy: 0.7994 - val_loss: 0.6066 - val_accuracy: 0.7640\n",
      "Epoch 88/300\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.5042 - accuracy: 0.8042 - val_loss: 0.6035 - val_accuracy: 0.7678\n",
      "Epoch 89/300\n",
      "301/301 [==============================] - 63s 210ms/step - loss: 0.5171 - accuracy: 0.7961 - val_loss: 0.5910 - val_accuracy: 0.7663\n",
      "Epoch 90/300\n",
      "301/301 [==============================] - 64s 212ms/step - loss: 0.5118 - accuracy: 0.7990 - val_loss: 0.5907 - val_accuracy: 0.7780\n",
      "Epoch 91/300\n",
      "301/301 [==============================] - 66s 218ms/step - loss: 0.5082 - accuracy: 0.8028 - val_loss: 0.6087 - val_accuracy: 0.7586\n",
      "Epoch 92/300\n",
      "301/301 [==============================] - 65s 215ms/step - loss: 0.4985 - accuracy: 0.8045 - val_loss: 0.6025 - val_accuracy: 0.7617\n",
      "Epoch 93/300\n",
      "301/301 [==============================] - 70s 232ms/step - loss: 0.5053 - accuracy: 0.7999 - val_loss: 0.6038 - val_accuracy: 0.7680\n",
      "Epoch 94/300\n",
      "301/301 [==============================] - 71s 234ms/step - loss: 0.5021 - accuracy: 0.8046 - val_loss: 0.6184 - val_accuracy: 0.7514\n",
      "Epoch 95/300\n",
      "301/301 [==============================] - 70s 233ms/step - loss: 0.5059 - accuracy: 0.8012 - val_loss: 0.6024 - val_accuracy: 0.7736\n",
      "Epoch 96/300\n",
      "301/301 [==============================] - 63s 209ms/step - loss: 0.5015 - accuracy: 0.8077 - val_loss: 0.5975 - val_accuracy: 0.7796\n",
      "Epoch 97/300\n",
      "301/301 [==============================] - 64s 214ms/step - loss: 0.5061 - accuracy: 0.8007 - val_loss: 0.5959 - val_accuracy: 0.7738\n",
      "Epoch 98/300\n",
      "301/301 [==============================] - 63s 210ms/step - loss: 0.4956 - accuracy: 0.8081 - val_loss: 0.6088 - val_accuracy: 0.7617\n",
      "Epoch 99/300\n",
      "301/301 [==============================] - 70s 232ms/step - loss: 0.5040 - accuracy: 0.8040 - val_loss: 0.5740 - val_accuracy: 0.7784\n",
      "Epoch 100/300\n",
      "301/301 [==============================] - 70s 233ms/step - loss: 0.4985 - accuracy: 0.8062 - val_loss: 0.5933 - val_accuracy: 0.7728\n",
      "Epoch 101/300\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.5039 - accuracy: 0.8024 - val_loss: 0.5946 - val_accuracy: 0.7719\n",
      "Epoch 102/300\n",
      "301/301 [==============================] - 63s 210ms/step - loss: 0.4970 - accuracy: 0.8046 - val_loss: 0.5826 - val_accuracy: 0.7796\n",
      "Epoch 103/300\n",
      "301/301 [==============================] - 62s 207ms/step - loss: 0.4919 - accuracy: 0.8080 - val_loss: 0.5853 - val_accuracy: 0.7759\n",
      "Epoch 104/300\n",
      "301/301 [==============================] - 66s 220ms/step - loss: 0.4968 - accuracy: 0.8059 - val_loss: 0.6115 - val_accuracy: 0.7620\n",
      "Epoch 105/300\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.5003 - accuracy: 0.8046 - val_loss: 0.5748 - val_accuracy: 0.7769\n",
      "Epoch 106/300\n",
      "301/301 [==============================] - 69s 230ms/step - loss: 0.4913 - accuracy: 0.8088 - val_loss: 0.6143 - val_accuracy: 0.7576\n",
      "Epoch 107/300\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.4914 - accuracy: 0.8079 - val_loss: 0.6030 - val_accuracy: 0.7615\n",
      "Epoch 108/300\n",
      "301/301 [==============================] - 61s 204ms/step - loss: 0.4923 - accuracy: 0.8071 - val_loss: 0.6231 - val_accuracy: 0.7545\n",
      "Epoch 109/300\n",
      "301/301 [==============================] - 62s 205ms/step - loss: 0.4980 - accuracy: 0.8036 - val_loss: 0.5796 - val_accuracy: 0.7751\n",
      "Epoch 110/300\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.4920 - accuracy: 0.8075 - val_loss: 0.6178 - val_accuracy: 0.7699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/300\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.4955 - accuracy: 0.8063 - val_loss: 0.5924 - val_accuracy: 0.7694\n",
      "Epoch 112/300\n",
      "301/301 [==============================] - 67s 221ms/step - loss: 0.4964 - accuracy: 0.8037 - val_loss: 0.6014 - val_accuracy: 0.7721\n",
      "Epoch 113/300\n",
      "301/301 [==============================] - 65s 214ms/step - loss: 0.4893 - accuracy: 0.8078 - val_loss: 0.5920 - val_accuracy: 0.7655\n",
      "Epoch 114/300\n",
      "301/301 [==============================] - 60s 200ms/step - loss: 0.4830 - accuracy: 0.8120 - val_loss: 0.5923 - val_accuracy: 0.7707\n",
      "Epoch 115/300\n",
      "301/301 [==============================] - 64s 212ms/step - loss: 0.4831 - accuracy: 0.8143 - val_loss: 0.5994 - val_accuracy: 0.7773\n",
      "Epoch 116/300\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.4825 - accuracy: 0.8118 - val_loss: 0.5948 - val_accuracy: 0.7782\n",
      "Epoch 117/300\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.4836 - accuracy: 0.8117 - val_loss: 0.5996 - val_accuracy: 0.7753\n",
      "Epoch 118/300\n",
      "301/301 [==============================] - 63s 208ms/step - loss: 0.4843 - accuracy: 0.8121 - val_loss: 0.5655 - val_accuracy: 0.7884\n",
      "Epoch 119/300\n",
      "301/301 [==============================] - 61s 202ms/step - loss: 0.4870 - accuracy: 0.8120 - val_loss: 0.6537 - val_accuracy: 0.7451\n",
      "Epoch 120/300\n",
      "301/301 [==============================] - 64s 213ms/step - loss: 0.4878 - accuracy: 0.8093 - val_loss: 0.6104 - val_accuracy: 0.7699\n",
      "Epoch 121/300\n",
      "301/301 [==============================] - 67s 222ms/step - loss: 0.4853 - accuracy: 0.8104 - val_loss: 0.5702 - val_accuracy: 0.7834\n",
      "Epoch 122/300\n",
      "301/301 [==============================] - 67s 223ms/step - loss: 0.4875 - accuracy: 0.8089 - val_loss: 0.6023 - val_accuracy: 0.7713\n",
      "Epoch 123/300\n",
      "301/301 [==============================] - 63s 210ms/step - loss: 0.4891 - accuracy: 0.8054 - val_loss: 0.5891 - val_accuracy: 0.7719\n",
      "Epoch 124/300\n",
      "301/301 [==============================] - 60s 200ms/step - loss: 0.4853 - accuracy: 0.8103 - val_loss: 0.5908 - val_accuracy: 0.7800\n",
      "Epoch 125/300\n",
      "301/301 [==============================] - 63s 210ms/step - loss: 0.4864 - accuracy: 0.8096 - val_loss: 0.5843 - val_accuracy: 0.7807\n",
      "Epoch 126/300\n",
      "301/301 [==============================] - 67s 223ms/step - loss: 0.4878 - accuracy: 0.8106 - val_loss: 0.6037 - val_accuracy: 0.7740\n",
      "Epoch 127/300\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.4827 - accuracy: 0.8118 - val_loss: 0.6002 - val_accuracy: 0.7738\n",
      "Epoch 128/300\n",
      "301/301 [==============================] - 64s 213ms/step - loss: 0.4731 - accuracy: 0.8166 - val_loss: 0.6093 - val_accuracy: 0.7751\n",
      "Epoch 129/300\n",
      "301/301 [==============================] - 62s 207ms/step - loss: 0.4753 - accuracy: 0.8142 - val_loss: 0.5861 - val_accuracy: 0.7796\n",
      "Epoch 130/300\n",
      "301/301 [==============================] - 61s 202ms/step - loss: 0.4881 - accuracy: 0.8079 - val_loss: 0.5882 - val_accuracy: 0.7800\n",
      "Epoch 131/300\n",
      "301/301 [==============================] - 64s 211ms/step - loss: 0.4765 - accuracy: 0.8165 - val_loss: 0.5963 - val_accuracy: 0.7740\n",
      "Epoch 132/300\n",
      "301/301 [==============================] - 66s 220ms/step - loss: 0.4779 - accuracy: 0.8118 - val_loss: 0.5944 - val_accuracy: 0.7738\n",
      "Epoch 133/300\n",
      "301/301 [==============================] - 66s 218ms/step - loss: 0.4798 - accuracy: 0.8131 - val_loss: 0.5948 - val_accuracy: 0.7761\n",
      "Epoch 134/300\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.4713 - accuracy: 0.8156 - val_loss: 0.6098 - val_accuracy: 0.7680\n",
      "Epoch 135/300\n",
      "301/301 [==============================] - 62s 206ms/step - loss: 0.4760 - accuracy: 0.8160 - val_loss: 0.5915 - val_accuracy: 0.7805\n",
      "Epoch 136/300\n",
      "301/301 [==============================] - 59s 196ms/step - loss: 0.4708 - accuracy: 0.8153 - val_loss: 0.6055 - val_accuracy: 0.7742\n",
      "Epoch 137/300\n",
      "301/301 [==============================] - 65s 216ms/step - loss: 0.4816 - accuracy: 0.8145 - val_loss: 0.5901 - val_accuracy: 0.7767\n",
      "Epoch 138/300\n",
      "301/301 [==============================] - 67s 223ms/step - loss: 0.4753 - accuracy: 0.8148 - val_loss: 0.5738 - val_accuracy: 0.7732\n",
      "Epoch 139/300\n",
      "301/301 [==============================] - 73s 241ms/step - loss: 0.4745 - accuracy: 0.8144 - val_loss: 0.6274 - val_accuracy: 0.7711\n",
      "Epoch 140/300\n",
      "301/301 [==============================] - 70s 231ms/step - loss: 0.4708 - accuracy: 0.8170 - val_loss: 0.5956 - val_accuracy: 0.7782\n",
      "Epoch 141/300\n",
      "301/301 [==============================] - 66s 219ms/step - loss: 0.4705 - accuracy: 0.8149 - val_loss: 0.6165 - val_accuracy: 0.7640\n",
      "Epoch 142/300\n",
      "301/301 [==============================] - 61s 202ms/step - loss: 0.4740 - accuracy: 0.8148 - val_loss: 0.6016 - val_accuracy: 0.7778\n",
      "Epoch 143/300\n",
      "301/301 [==============================] - 65s 217ms/step - loss: 0.4674 - accuracy: 0.8188 - val_loss: 0.6193 - val_accuracy: 0.7642\n",
      "Epoch 144/300\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.4786 - accuracy: 0.8140 - val_loss: 0.6147 - val_accuracy: 0.7742\n",
      "Epoch 145/300\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.4712 - accuracy: 0.8142 - val_loss: 0.6129 - val_accuracy: 0.7719\n",
      "Epoch 146/300\n",
      "301/301 [==============================] - 63s 209ms/step - loss: 0.4722 - accuracy: 0.8182 - val_loss: 0.6053 - val_accuracy: 0.7703\n",
      "Epoch 147/300\n",
      "301/301 [==============================] - 61s 202ms/step - loss: 0.4669 - accuracy: 0.8185 - val_loss: 0.6022 - val_accuracy: 0.7694\n",
      "Epoch 148/300\n",
      "301/301 [==============================] - 63s 210ms/step - loss: 0.4712 - accuracy: 0.8154 - val_loss: 0.6030 - val_accuracy: 0.7742\n",
      "Epoch 149/300\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.4704 - accuracy: 0.8181 - val_loss: 0.6266 - val_accuracy: 0.7649\n",
      "Epoch 150/300\n",
      "301/301 [==============================] - 67s 223ms/step - loss: 0.4673 - accuracy: 0.8157 - val_loss: 0.6186 - val_accuracy: 0.7709\n",
      "Epoch 151/300\n",
      "301/301 [==============================] - 66s 220ms/step - loss: 0.4626 - accuracy: 0.8192 - val_loss: 0.5939 - val_accuracy: 0.7765\n",
      "Epoch 152/300\n",
      "301/301 [==============================] - 64s 211ms/step - loss: 0.4647 - accuracy: 0.8155 - val_loss: 0.5899 - val_accuracy: 0.7842\n",
      "Epoch 153/300\n",
      "301/301 [==============================] - 59s 198ms/step - loss: 0.4664 - accuracy: 0.8172 - val_loss: 0.6060 - val_accuracy: 0.7721\n",
      "Epoch 154/300\n",
      "301/301 [==============================] - 66s 221ms/step - loss: 0.4632 - accuracy: 0.8208 - val_loss: 0.6098 - val_accuracy: 0.7665\n",
      "Epoch 155/300\n",
      "301/301 [==============================] - 67s 223ms/step - loss: 0.4751 - accuracy: 0.8142 - val_loss: 0.6138 - val_accuracy: 0.7701\n",
      "Epoch 156/300\n",
      "301/301 [==============================] - 67s 223ms/step - loss: 0.4629 - accuracy: 0.8180 - val_loss: 0.6197 - val_accuracy: 0.7780\n",
      "Epoch 157/300\n",
      "301/301 [==============================] - 64s 211ms/step - loss: 0.4638 - accuracy: 0.8191 - val_loss: 0.6087 - val_accuracy: 0.7728\n",
      "Epoch 158/300\n",
      "301/301 [==============================] - 61s 204ms/step - loss: 0.4672 - accuracy: 0.8174 - val_loss: 0.6019 - val_accuracy: 0.7790\n",
      "Epoch 159/300\n",
      "301/301 [==============================] - 61s 201ms/step - loss: 0.4655 - accuracy: 0.8198 - val_loss: 0.5965 - val_accuracy: 0.7755\n",
      "Epoch 160/300\n",
      "301/301 [==============================] - 65s 217ms/step - loss: 0.4690 - accuracy: 0.8192 - val_loss: 0.6273 - val_accuracy: 0.7665\n",
      "Epoch 161/300\n",
      "301/301 [==============================] - 67s 222ms/step - loss: 0.4671 - accuracy: 0.8179 - val_loss: 0.6180 - val_accuracy: 0.7713\n",
      "Epoch 162/300\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.4696 - accuracy: 0.8148 - val_loss: 0.5865 - val_accuracy: 0.7767\n",
      "Epoch 163/300\n",
      "301/301 [==============================] - 60s 200ms/step - loss: 0.4612 - accuracy: 0.8199 - val_loss: 0.5916 - val_accuracy: 0.7850\n",
      "Epoch 164/300\n",
      "301/301 [==============================] - 60s 198ms/step - loss: 0.4632 - accuracy: 0.8187 - val_loss: 0.6018 - val_accuracy: 0.7825\n",
      "Epoch 165/300\n",
      "301/301 [==============================] - 65s 217ms/step - loss: 0.4633 - accuracy: 0.8210 - val_loss: 0.6193 - val_accuracy: 0.7767\n",
      "Epoch 166/300\n",
      "301/301 [==============================] - 67s 223ms/step - loss: 0.4612 - accuracy: 0.8191 - val_loss: 0.6043 - val_accuracy: 0.7676\n",
      "Epoch 167/300\n",
      "301/301 [==============================] - 67s 223ms/step - loss: 0.4535 - accuracy: 0.8235 - val_loss: 0.6065 - val_accuracy: 0.7817\n",
      "Epoch 168/300\n",
      "301/301 [==============================] - 62s 205ms/step - loss: 0.4599 - accuracy: 0.8201 - val_loss: 0.5987 - val_accuracy: 0.7792\n",
      "Epoch 169/300\n",
      "301/301 [==============================] - 61s 203ms/step - loss: 0.4647 - accuracy: 0.8162 - val_loss: 0.6076 - val_accuracy: 0.7825\n",
      "Epoch 170/300\n",
      "301/301 [==============================] - 63s 208ms/step - loss: 0.4570 - accuracy: 0.8210 - val_loss: 0.6014 - val_accuracy: 0.7823\n",
      "Epoch 171/300\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.4644 - accuracy: 0.8203 - val_loss: 0.6042 - val_accuracy: 0.7692\n",
      "Epoch 172/300\n",
      "301/301 [==============================] - 67s 223ms/step - loss: 0.4554 - accuracy: 0.8212 - val_loss: 0.5940 - val_accuracy: 0.7821\n",
      "Epoch 173/300\n",
      "301/301 [==============================] - 62s 206ms/step - loss: 0.4611 - accuracy: 0.8195 - val_loss: 0.6087 - val_accuracy: 0.7703\n",
      "Epoch 174/300\n",
      "301/301 [==============================] - 59s 195ms/step - loss: 0.4618 - accuracy: 0.8175 - val_loss: 0.6224 - val_accuracy: 0.7738\n",
      "Epoch 175/300\n",
      "301/301 [==============================] - 65s 217ms/step - loss: 0.4550 - accuracy: 0.8235 - val_loss: 0.5890 - val_accuracy: 0.7802\n",
      "Epoch 176/300\n",
      "301/301 [==============================] - 69s 228ms/step - loss: 0.4580 - accuracy: 0.8209 - val_loss: 0.6017 - val_accuracy: 0.7784\n",
      "Epoch 177/300\n",
      "301/301 [==============================] - 66s 221ms/step - loss: 0.4626 - accuracy: 0.8194 - val_loss: 0.6167 - val_accuracy: 0.7688\n",
      "Epoch 178/300\n",
      "301/301 [==============================] - 62s 207ms/step - loss: 0.4583 - accuracy: 0.8217 - val_loss: 0.6207 - val_accuracy: 0.7628\n",
      "Epoch 179/300\n",
      "301/301 [==============================] - 60s 200ms/step - loss: 0.4542 - accuracy: 0.8204 - val_loss: 0.6382 - val_accuracy: 0.7632\n",
      "Epoch 180/300\n",
      "301/301 [==============================] - 63s 210ms/step - loss: 0.4545 - accuracy: 0.8217 - val_loss: 0.6026 - val_accuracy: 0.7809\n",
      "Epoch 181/300\n",
      "301/301 [==============================] - 67s 223ms/step - loss: 0.4501 - accuracy: 0.8231 - val_loss: 0.6129 - val_accuracy: 0.7794\n",
      "Epoch 182/300\n",
      "301/301 [==============================] - 67s 222ms/step - loss: 0.4629 - accuracy: 0.8186 - val_loss: 0.6221 - val_accuracy: 0.7651\n",
      "Epoch 183/300\n",
      "301/301 [==============================] - 64s 212ms/step - loss: 0.4530 - accuracy: 0.8272 - val_loss: 0.5939 - val_accuracy: 0.7830\n",
      "Epoch 184/300\n",
      "301/301 [==============================] - 62s 206ms/step - loss: 0.4554 - accuracy: 0.8234 - val_loss: 0.6237 - val_accuracy: 0.7642\n",
      "Epoch 185/300\n",
      "301/301 [==============================] - 60s 199ms/step - loss: 0.4507 - accuracy: 0.8251 - val_loss: 0.5939 - val_accuracy: 0.7840\n",
      "Epoch 186/300\n",
      "301/301 [==============================] - 65s 217ms/step - loss: 0.4533 - accuracy: 0.8239 - val_loss: 0.6314 - val_accuracy: 0.7644\n",
      "Epoch 187/300\n",
      "301/301 [==============================] - 66s 220ms/step - loss: 0.4563 - accuracy: 0.8192 - val_loss: 0.5988 - val_accuracy: 0.7867\n",
      "Epoch 188/300\n",
      "301/301 [==============================] - 66s 221ms/step - loss: 0.4465 - accuracy: 0.8250 - val_loss: 0.6134 - val_accuracy: 0.7723\n",
      "Epoch 189/300\n",
      "301/301 [==============================] - 63s 210ms/step - loss: 0.4577 - accuracy: 0.8184 - val_loss: 0.6072 - val_accuracy: 0.7696\n",
      "Epoch 190/300\n",
      "301/301 [==============================] - 61s 201ms/step - loss: 0.4577 - accuracy: 0.8226 - val_loss: 0.6118 - val_accuracy: 0.7732\n",
      "Epoch 191/300\n",
      "301/301 [==============================] - 62s 205ms/step - loss: 0.4547 - accuracy: 0.8245 - val_loss: 0.6053 - val_accuracy: 0.7757\n",
      "Epoch 192/300\n",
      "301/301 [==============================] - 66s 221ms/step - loss: 0.4576 - accuracy: 0.8204 - val_loss: 0.5920 - val_accuracy: 0.7763\n",
      "Epoch 193/300\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.4510 - accuracy: 0.8221 - val_loss: 0.6399 - val_accuracy: 0.7634\n",
      "Epoch 194/300\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.4556 - accuracy: 0.8218 - val_loss: 0.5977 - val_accuracy: 0.7875\n",
      "Epoch 195/300\n",
      "301/301 [==============================] - 61s 202ms/step - loss: 0.4542 - accuracy: 0.8220 - val_loss: 0.6110 - val_accuracy: 0.7817\n",
      "Epoch 196/300\n",
      "301/301 [==============================] - 60s 199ms/step - loss: 0.4468 - accuracy: 0.8261 - val_loss: 0.6106 - val_accuracy: 0.7682\n",
      "Epoch 197/300\n",
      "301/301 [==============================] - 66s 219ms/step - loss: 0.4550 - accuracy: 0.8205 - val_loss: 0.6149 - val_accuracy: 0.7680\n",
      "Epoch 198/300\n",
      "301/301 [==============================] - 65s 217ms/step - loss: 0.4465 - accuracy: 0.8253 - val_loss: 0.6095 - val_accuracy: 0.7753\n",
      "Epoch 199/300\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.4595 - accuracy: 0.8203 - val_loss: 0.5949 - val_accuracy: 0.7778\n",
      "Epoch 200/300\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.4478 - accuracy: 0.8239 - val_loss: 0.6183 - val_accuracy: 0.7734\n",
      "Epoch 201/300\n",
      "301/301 [==============================] - 67s 221ms/step - loss: 0.4469 - accuracy: 0.8261 - val_loss: 0.5932 - val_accuracy: 0.7836\n",
      "Epoch 202/300\n",
      "301/301 [==============================] - 63s 209ms/step - loss: 0.4458 - accuracy: 0.8247 - val_loss: 0.6085 - val_accuracy: 0.7904\n",
      "Epoch 203/300\n",
      "301/301 [==============================] - 61s 202ms/step - loss: 0.4442 - accuracy: 0.8260 - val_loss: 0.6206 - val_accuracy: 0.7719\n",
      "Epoch 204/300\n",
      "301/301 [==============================] - 64s 212ms/step - loss: 0.4488 - accuracy: 0.8236 - val_loss: 0.6032 - val_accuracy: 0.7751\n",
      "Epoch 205/300\n",
      "301/301 [==============================] - 66s 220ms/step - loss: 0.4457 - accuracy: 0.8275 - val_loss: 0.5952 - val_accuracy: 0.7753\n",
      "Epoch 206/300\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.4506 - accuracy: 0.8228 - val_loss: 0.6037 - val_accuracy: 0.7898\n",
      "Epoch 207/300\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.4432 - accuracy: 0.8271 - val_loss: 0.6005 - val_accuracy: 0.7773\n",
      "Epoch 208/300\n",
      "301/301 [==============================] - 63s 209ms/step - loss: 0.4412 - accuracy: 0.8274 - val_loss: 0.6066 - val_accuracy: 0.7800\n",
      "Epoch 209/300\n",
      "301/301 [==============================] - 60s 201ms/step - loss: 0.4485 - accuracy: 0.8252 - val_loss: 0.5999 - val_accuracy: 0.7809\n",
      "Epoch 210/300\n",
      "301/301 [==============================] - 65s 218ms/step - loss: 0.4473 - accuracy: 0.8219 - val_loss: 0.6146 - val_accuracy: 0.7755\n",
      "Epoch 211/300\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.4484 - accuracy: 0.8252 - val_loss: 0.5889 - val_accuracy: 0.7807\n",
      "Epoch 212/300\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.4413 - accuracy: 0.8266 - val_loss: 0.5941 - val_accuracy: 0.7780\n",
      "Epoch 213/300\n",
      "301/301 [==============================] - 67s 221ms/step - loss: 0.4359 - accuracy: 0.8274 - val_loss: 0.6246 - val_accuracy: 0.7761\n",
      "Epoch 214/300\n",
      "301/301 [==============================] - 62s 207ms/step - loss: 0.4452 - accuracy: 0.8268 - val_loss: 0.5915 - val_accuracy: 0.7825\n",
      "Epoch 215/300\n",
      "301/301 [==============================] - 61s 204ms/step - loss: 0.4519 - accuracy: 0.8264 - val_loss: 0.5868 - val_accuracy: 0.7748\n",
      "Epoch 216/300\n",
      "301/301 [==============================] - 62s 206ms/step - loss: 0.4380 - accuracy: 0.8285 - val_loss: 0.6020 - val_accuracy: 0.7840\n",
      "Epoch 217/300\n",
      "301/301 [==============================] - 68s 224ms/step - loss: 0.4441 - accuracy: 0.8262 - val_loss: 0.5951 - val_accuracy: 0.7784\n",
      "Epoch 218/300\n",
      "301/301 [==============================] - 67s 223ms/step - loss: 0.4416 - accuracy: 0.8286 - val_loss: 0.6281 - val_accuracy: 0.7682\n",
      "Epoch 219/300\n",
      "301/301 [==============================] - 66s 219ms/step - loss: 0.4573 - accuracy: 0.8234 - val_loss: 0.5719 - val_accuracy: 0.7857\n",
      "Epoch 220/300\n",
      "301/301 [==============================] - 60s 198ms/step - loss: 0.4437 - accuracy: 0.8264 - val_loss: 0.6151 - val_accuracy: 0.7765\n",
      "Epoch 221/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 61s 203ms/step - loss: 0.4404 - accuracy: 0.8244 - val_loss: 0.6033 - val_accuracy: 0.7788\n",
      "Epoch 222/300\n",
      "301/301 [==============================] - 66s 220ms/step - loss: 0.4454 - accuracy: 0.8279 - val_loss: 0.5972 - val_accuracy: 0.7784\n",
      "Epoch 223/300\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.4447 - accuracy: 0.8233 - val_loss: 0.5964 - val_accuracy: 0.7744\n",
      "Epoch 224/300\n",
      "301/301 [==============================] - 67s 222ms/step - loss: 0.4469 - accuracy: 0.8247 - val_loss: 0.6029 - val_accuracy: 0.7852\n",
      "Epoch 225/300\n",
      "301/301 [==============================] - 61s 202ms/step - loss: 0.4480 - accuracy: 0.8225 - val_loss: 0.6063 - val_accuracy: 0.7753\n",
      "Epoch 226/300\n",
      "301/301 [==============================] - 62s 205ms/step - loss: 0.4420 - accuracy: 0.8291 - val_loss: 0.6008 - val_accuracy: 0.7780\n",
      "Epoch 227/300\n",
      "301/301 [==============================] - 64s 213ms/step - loss: 0.4427 - accuracy: 0.8276 - val_loss: 0.6162 - val_accuracy: 0.7771\n",
      "Epoch 228/300\n",
      "301/301 [==============================] - 67s 223ms/step - loss: 0.4333 - accuracy: 0.8312 - val_loss: 0.6169 - val_accuracy: 0.7713\n",
      "Epoch 229/300\n",
      "301/301 [==============================] - 67s 222ms/step - loss: 0.4329 - accuracy: 0.8324 - val_loss: 0.5989 - val_accuracy: 0.7817\n",
      "Epoch 230/300\n",
      "301/301 [==============================] - 62s 205ms/step - loss: 0.4510 - accuracy: 0.8246 - val_loss: 0.5920 - val_accuracy: 0.7798\n",
      "Epoch 231/300\n",
      "301/301 [==============================] - 62s 204ms/step - loss: 0.4418 - accuracy: 0.8266 - val_loss: 0.6244 - val_accuracy: 0.7711\n",
      "Epoch 232/300\n",
      "301/301 [==============================] - 62s 207ms/step - loss: 0.4444 - accuracy: 0.8245 - val_loss: 0.6008 - val_accuracy: 0.7811\n",
      "Epoch 233/300\n",
      "301/301 [==============================] - 66s 220ms/step - loss: 0.4425 - accuracy: 0.8272 - val_loss: 0.6453 - val_accuracy: 0.7557\n",
      "Epoch 234/300\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.4359 - accuracy: 0.8304 - val_loss: 0.6054 - val_accuracy: 0.7823\n",
      "Epoch 235/300\n",
      "301/301 [==============================] - 66s 218ms/step - loss: 0.4355 - accuracy: 0.8308 - val_loss: 0.6051 - val_accuracy: 0.7755\n",
      "Epoch 236/300\n",
      "301/301 [==============================] - 62s 204ms/step - loss: 0.4428 - accuracy: 0.8299 - val_loss: 0.6167 - val_accuracy: 0.7765\n",
      "Epoch 237/300\n",
      "301/301 [==============================] - 60s 199ms/step - loss: 0.4331 - accuracy: 0.8307 - val_loss: 0.6110 - val_accuracy: 0.7767\n",
      "Epoch 238/300\n",
      "301/301 [==============================] - 67s 223ms/step - loss: 0.4409 - accuracy: 0.8314 - val_loss: 0.6200 - val_accuracy: 0.7703\n",
      "Epoch 239/300\n",
      "301/301 [==============================] - 67s 222ms/step - loss: 0.4350 - accuracy: 0.8311 - val_loss: 0.6095 - val_accuracy: 0.7738\n",
      "Epoch 240/300\n",
      "301/301 [==============================] - 67s 223ms/step - loss: 0.4420 - accuracy: 0.8301 - val_loss: 0.5974 - val_accuracy: 0.7773\n",
      "Epoch 241/300\n",
      "301/301 [==============================] - 61s 204ms/step - loss: 0.4360 - accuracy: 0.8311 - val_loss: 0.6018 - val_accuracy: 0.7798\n",
      "Epoch 242/300\n",
      "301/301 [==============================] - 59s 197ms/step - loss: 0.4376 - accuracy: 0.8294 - val_loss: 0.6095 - val_accuracy: 0.7782\n",
      "Epoch 243/300\n",
      "301/301 [==============================] - 65s 217ms/step - loss: 0.4354 - accuracy: 0.8272 - val_loss: 0.6157 - val_accuracy: 0.7757\n",
      "Epoch 244/300\n",
      "301/301 [==============================] - 66s 219ms/step - loss: 0.4372 - accuracy: 0.8309 - val_loss: 0.5985 - val_accuracy: 0.7763\n",
      "Epoch 245/300\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.4408 - accuracy: 0.8306 - val_loss: 0.6169 - val_accuracy: 0.7732\n",
      "Epoch 246/300\n",
      "301/301 [==============================] - 62s 205ms/step - loss: 0.4387 - accuracy: 0.8310 - val_loss: 0.6094 - val_accuracy: 0.7771\n",
      "Epoch 247/300\n",
      "301/301 [==============================] - 59s 198ms/step - loss: 0.4413 - accuracy: 0.8275 - val_loss: 0.6046 - val_accuracy: 0.7734\n",
      "Epoch 248/300\n",
      "301/301 [==============================] - 65s 215ms/step - loss: 0.4239 - accuracy: 0.8351 - val_loss: 0.6301 - val_accuracy: 0.7678\n",
      "Epoch 249/300\n",
      "301/301 [==============================] - 67s 222ms/step - loss: 0.4396 - accuracy: 0.8300 - val_loss: 0.5907 - val_accuracy: 0.7852\n",
      "Epoch 250/300\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.4308 - accuracy: 0.8317 - val_loss: 0.6281 - val_accuracy: 0.7638\n",
      "Epoch 251/300\n",
      "301/301 [==============================] - 67s 222ms/step - loss: 0.4420 - accuracy: 0.8293 - val_loss: 0.6557 - val_accuracy: 0.7549\n",
      "Epoch 252/300\n",
      "301/301 [==============================] - 61s 204ms/step - loss: 0.4259 - accuracy: 0.8364 - val_loss: 0.6230 - val_accuracy: 0.7784\n",
      "Epoch 253/300\n",
      "301/301 [==============================] - 61s 201ms/step - loss: 0.4350 - accuracy: 0.8295 - val_loss: 0.6211 - val_accuracy: 0.7711\n",
      "Epoch 254/300\n",
      "301/301 [==============================] - 65s 216ms/step - loss: 0.4283 - accuracy: 0.8358 - val_loss: 0.5857 - val_accuracy: 0.7886\n",
      "Epoch 255/300\n",
      "301/301 [==============================] - 67s 223ms/step - loss: 0.4329 - accuracy: 0.8311 - val_loss: 0.6373 - val_accuracy: 0.7669\n",
      "Epoch 256/300\n",
      "301/301 [==============================] - 66s 221ms/step - loss: 0.4308 - accuracy: 0.8322 - val_loss: 0.5958 - val_accuracy: 0.7734\n",
      "Epoch 257/300\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.4304 - accuracy: 0.8314 - val_loss: 0.6338 - val_accuracy: 0.7726\n",
      "Epoch 258/300\n",
      "301/301 [==============================] - 65s 216ms/step - loss: 0.4300 - accuracy: 0.8318 - val_loss: 0.6073 - val_accuracy: 0.7751\n",
      "Epoch 259/300\n",
      "301/301 [==============================] - 61s 204ms/step - loss: 0.4336 - accuracy: 0.8306 - val_loss: 0.6391 - val_accuracy: 0.7686\n",
      "Epoch 260/300\n",
      "301/301 [==============================] - 62s 205ms/step - loss: 0.4463 - accuracy: 0.8241 - val_loss: 0.6118 - val_accuracy: 0.7748\n",
      "Epoch 261/300\n",
      "301/301 [==============================] - 66s 218ms/step - loss: 0.4275 - accuracy: 0.8321 - val_loss: 0.6219 - val_accuracy: 0.7707\n",
      "Epoch 262/300\n",
      "301/301 [==============================] - 67s 222ms/step - loss: 0.4275 - accuracy: 0.8303 - val_loss: 0.6252 - val_accuracy: 0.7748\n",
      "Epoch 263/300\n",
      "301/301 [==============================] - 68s 227ms/step - loss: 0.4286 - accuracy: 0.8350 - val_loss: 0.6085 - val_accuracy: 0.7726\n",
      "Epoch 264/300\n",
      "301/301 [==============================] - 61s 201ms/step - loss: 0.4261 - accuracy: 0.8340 - val_loss: 0.6169 - val_accuracy: 0.7715\n",
      "Epoch 265/300\n",
      "301/301 [==============================] - 60s 198ms/step - loss: 0.4289 - accuracy: 0.8307 - val_loss: 0.6136 - val_accuracy: 0.7726\n",
      "Epoch 266/300\n",
      "301/301 [==============================] - 67s 221ms/step - loss: 0.4401 - accuracy: 0.8304 - val_loss: 0.5868 - val_accuracy: 0.7730\n",
      "Epoch 267/300\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.4340 - accuracy: 0.8316 - val_loss: 0.6185 - val_accuracy: 0.7753\n",
      "Epoch 268/300\n",
      "301/301 [==============================] - 66s 219ms/step - loss: 0.4375 - accuracy: 0.8301 - val_loss: 0.5829 - val_accuracy: 0.7840\n",
      "Epoch 269/300\n",
      "301/301 [==============================] - 68s 226ms/step - loss: 0.4268 - accuracy: 0.8347 - val_loss: 0.6427 - val_accuracy: 0.7628\n",
      "Epoch 270/300\n",
      "301/301 [==============================] - 63s 211ms/step - loss: 0.4327 - accuracy: 0.8321 - val_loss: 0.5970 - val_accuracy: 0.7796\n",
      "Epoch 271/300\n",
      "301/301 [==============================] - 61s 202ms/step - loss: 0.4353 - accuracy: 0.8330 - val_loss: 0.6028 - val_accuracy: 0.7703\n",
      "Epoch 272/300\n",
      "301/301 [==============================] - 62s 205ms/step - loss: 0.4291 - accuracy: 0.8317 - val_loss: 0.5729 - val_accuracy: 0.7906\n",
      "Epoch 273/300\n",
      "301/301 [==============================] - 65s 217ms/step - loss: 0.4234 - accuracy: 0.8345 - val_loss: 0.6014 - val_accuracy: 0.7848\n",
      "Epoch 274/300\n",
      "301/301 [==============================] - 67s 223ms/step - loss: 0.4378 - accuracy: 0.8324 - val_loss: 0.6052 - val_accuracy: 0.7838\n",
      "Epoch 275/300\n",
      "301/301 [==============================] - 67s 221ms/step - loss: 0.4342 - accuracy: 0.8298 - val_loss: 0.6140 - val_accuracy: 0.7771\n",
      "Epoch 276/300\n",
      "301/301 [==============================] - 65s 216ms/step - loss: 0.4228 - accuracy: 0.8356 - val_loss: 0.5996 - val_accuracy: 0.7782\n",
      "Epoch 277/300\n",
      "301/301 [==============================] - 59s 198ms/step - loss: 0.4336 - accuracy: 0.8319 - val_loss: 0.6051 - val_accuracy: 0.7817\n",
      "Epoch 278/300\n",
      "301/301 [==============================] - 63s 210ms/step - loss: 0.4233 - accuracy: 0.8346 - val_loss: 0.5954 - val_accuracy: 0.7861\n",
      "Epoch 279/300\n",
      "301/301 [==============================] - 66s 219ms/step - loss: 0.4270 - accuracy: 0.8301 - val_loss: 0.6198 - val_accuracy: 0.7701\n",
      "Epoch 280/300\n",
      "301/301 [==============================] - 66s 221ms/step - loss: 0.4266 - accuracy: 0.8323 - val_loss: 0.5800 - val_accuracy: 0.7817\n",
      "Epoch 281/300\n",
      "301/301 [==============================] - 66s 220ms/step - loss: 0.4275 - accuracy: 0.8345 - val_loss: 0.6240 - val_accuracy: 0.7703\n",
      "Epoch 282/300\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.4212 - accuracy: 0.8351 - val_loss: 0.6104 - val_accuracy: 0.7717\n",
      "Epoch 283/300\n",
      "301/301 [==============================] - 63s 208ms/step - loss: 0.4229 - accuracy: 0.8367 - val_loss: 0.6072 - val_accuracy: 0.7786\n",
      "Epoch 284/300\n",
      "301/301 [==============================] - 62s 206ms/step - loss: 0.4394 - accuracy: 0.8280 - val_loss: 0.5770 - val_accuracy: 0.7884\n",
      "Epoch 285/300\n",
      "301/301 [==============================] - 62s 205ms/step - loss: 0.4311 - accuracy: 0.8347 - val_loss: 0.5966 - val_accuracy: 0.7852\n",
      "Epoch 286/300\n",
      "301/301 [==============================] - 65s 215ms/step - loss: 0.4229 - accuracy: 0.8353 - val_loss: 0.6109 - val_accuracy: 0.7713\n",
      "Epoch 287/300\n",
      "301/301 [==============================] - 67s 221ms/step - loss: 0.4201 - accuracy: 0.8348 - val_loss: 0.6203 - val_accuracy: 0.7728\n",
      "Epoch 288/300\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.4237 - accuracy: 0.8348 - val_loss: 0.6078 - val_accuracy: 0.7854\n",
      "Epoch 289/300\n",
      "301/301 [==============================] - 66s 221ms/step - loss: 0.4221 - accuracy: 0.8341 - val_loss: 0.6152 - val_accuracy: 0.7699\n",
      "Epoch 290/300\n",
      "301/301 [==============================] - 60s 199ms/step - loss: 0.4211 - accuracy: 0.8386 - val_loss: 0.5850 - val_accuracy: 0.7809\n",
      "Epoch 291/300\n",
      "301/301 [==============================] - 60s 199ms/step - loss: 0.4219 - accuracy: 0.8341 - val_loss: 0.5748 - val_accuracy: 0.7921\n",
      "Epoch 292/300\n",
      "301/301 [==============================] - 66s 221ms/step - loss: 0.4121 - accuracy: 0.8396 - val_loss: 0.6099 - val_accuracy: 0.7834\n",
      "Epoch 293/300\n",
      "301/301 [==============================] - 67s 224ms/step - loss: 0.4234 - accuracy: 0.8361 - val_loss: 0.5917 - val_accuracy: 0.7734\n",
      "Epoch 294/300\n",
      "301/301 [==============================] - 67s 222ms/step - loss: 0.4249 - accuracy: 0.8336 - val_loss: 0.6325 - val_accuracy: 0.7692\n",
      "Epoch 295/300\n",
      "301/301 [==============================] - 62s 205ms/step - loss: 0.4190 - accuracy: 0.8361 - val_loss: 0.6070 - val_accuracy: 0.7825\n",
      "Epoch 296/300\n",
      "301/301 [==============================] - 62s 206ms/step - loss: 0.4187 - accuracy: 0.8383 - val_loss: 0.6005 - val_accuracy: 0.7830\n",
      "Epoch 297/300\n",
      "301/301 [==============================] - 63s 208ms/step - loss: 0.4236 - accuracy: 0.8357 - val_loss: 0.6163 - val_accuracy: 0.7740\n",
      "Epoch 298/300\n",
      "301/301 [==============================] - 67s 223ms/step - loss: 0.4249 - accuracy: 0.8329 - val_loss: 0.6098 - val_accuracy: 0.7713\n",
      "Epoch 299/300\n",
      "301/301 [==============================] - 68s 225ms/step - loss: 0.4242 - accuracy: 0.8362 - val_loss: 0.5962 - val_accuracy: 0.7755\n",
      "Epoch 300/300\n",
      "301/301 [==============================] - 64s 213ms/step - loss: 0.4256 - accuracy: 0.8334 - val_loss: 0.6089 - val_accuracy: 0.7674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a02a710708>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    training_data,\n",
    "    validation_data=testing_data,\n",
    "    epochs=300,\n",
    "    steps_per_epoch=len(training_data),\n",
    "    validation_steps=len(testing_data),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"detection_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
